{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_local(file_path):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    parsed = [line.strip().split(';') for line in lines]\n",
    "    max_len = max(len(row) for row in parsed)\n",
    "    colnames = [f'col{i}' for i in range(max_len)]\n",
    "    df = pd.DataFrame(parsed, columns=colnames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:01:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151261</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:03:20</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151262</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:04:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151263</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:04:02</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151264</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:05:03</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458151265</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  col0  col1       col2        col3     col4           col5\n",
       "0  2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
       "1  2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
       "2  2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
       "3  2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
       "4  2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"dilans_data.csv\"\n",
    "raw_df = load_data_local(file_path)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_SOURCES = {'Reddit', 'SEO', 'AdWords'}\n",
    "\n",
    "def parse_read_event(fields, i):\n",
    "    dt = fields[i]\n",
    "    country = fields[i+2]\n",
    "    user_id = fields[i+3]\n",
    "\n",
    "    if fields[i+4] in KNOWN_SOURCES:\n",
    "        source = fields[i+4]\n",
    "        topic = fields[i+5]\n",
    "        return {\n",
    "            'datetime': dt,\n",
    "            'event_type': 'read',\n",
    "            'country': country,\n",
    "            'user_id': user_id,\n",
    "            'source': source,\n",
    "            'topic': topic\n",
    "        }, 6\n",
    "    else:\n",
    "        topic = fields[i+4]\n",
    "        return {\n",
    "            'datetime': dt,\n",
    "            'event_type': 'read',\n",
    "            'country': country,\n",
    "            'user_id': user_id,\n",
    "            'source': 'Returning',\n",
    "            'topic': topic\n",
    "        }, 5\n",
    "\n",
    "def parse_subscribe_event(fields, i):\n",
    "    return {\n",
    "        'datetime': fields[i],\n",
    "        'event_type': 'subscribe',\n",
    "        'user_id': fields[i+2]\n",
    "    }, 3\n",
    "\n",
    "def parse_buy_event(fields, i):\n",
    "    return {\n",
    "        'datetime': fields[i],\n",
    "        'event_type': 'buy',\n",
    "        'user_id': fields[i+2],\n",
    "        'price': fields[i+3]\n",
    "    }, 4\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    read_rows, subscribe_rows, buy_rows = [], [], []\n",
    "\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(';')\n",
    "            i = 0\n",
    "            while i < len(fields):\n",
    "                try:\n",
    "                    event_type = fields[i+1]\n",
    "\n",
    "                    if event_type == 'read':\n",
    "                        record, step = parse_read_event(fields, i)\n",
    "                        read_rows.append(record)\n",
    "                    elif event_type == 'subscribe':\n",
    "                        record, step = parse_subscribe_event(fields, i)\n",
    "                        subscribe_rows.append(record)\n",
    "                    elif event_type == 'buy':\n",
    "                        record, step = parse_buy_event(fields, i)\n",
    "                        buy_rows.append(record)\n",
    "                    else:\n",
    "                        step = 1\n",
    "\n",
    "                    i += step\n",
    "\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "    return (\n",
    "        clean_read_df(read_rows),\n",
    "        clean_subscribe_df(subscribe_rows),\n",
    "        clean_buy_df(buy_rows)\n",
    "    )\n",
    "\n",
    "def clean_read_df(rows):\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def clean_subscribe_df(rows):\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def clean_buy_df(rows):\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df, subscribe_df, buy_df = parse_log_file(\"dilans_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataframes(read_df, subscribe_df, buy_df):\n",
    "    print(\"=== BASIC STRUCTURE & NULLS ===\")\n",
    "    for df, name in zip([read_df, subscribe_df, buy_df], ['read', 'subscribe', 'buy']):\n",
    "        print(f\"\\n{name.upper()} DF SHAPE: {df.shape}\")\n",
    "        print(f\"{name} nulls:\\n\", df.isnull().sum())\n",
    "        print(f\"{name} dtypes:\\n\", df.dtypes)\n",
    "\n",
    "    print(\"\\n=== UNIQUE VALUES IN READ_DF ===\")\n",
    "    print(\"Countries:\", read_df['country'].unique())\n",
    "    print(\"Sources:\", read_df['source'].unique())\n",
    "    print(\"Topics:\", read_df['topic'].unique())\n",
    "\n",
    "    print(\"\\n=== VALUE CHECKS ===\")\n",
    "    print(\"Invalid countries:\\n\", read_df[~read_df['country'].str.startswith(\"country_\")])\n",
    "    print(\"Invalid sources:\\n\", read_df[~read_df['source'].isin(['Reddit', 'AdWords', 'SEO', 'Returning'])])\n",
    "\n",
    "    print(\"\\n=== DUPLICATE CHECKS ===\")\n",
    "    print(\"Duplicate read events:\", read_df.duplicated().sum())\n",
    "    print(\"Duplicate subscriptions:\", subscribe_df.duplicated().sum())\n",
    "\n",
    "    print(\"\\n=== USER ACTIVITY ===\")\n",
    "    print(\"Reads per user (top 10):\\n\", read_df['user_id'].value_counts().head(10))\n",
    "    subscribers_not_readers = set(subscribe_df['user_id']) - set(read_df['user_id'])\n",
    "    print(\"Subscribers not in read_df:\", len(subscribers_not_readers))\n",
    "\n",
    "    buyers = set(buy_df['user_id'])\n",
    "    readers = set(read_df['user_id'])\n",
    "    subscribers = set(subscribe_df['user_id'])\n",
    "    print(\"Buyers not in read_df:\", len(buyers - readers))\n",
    "    print(\"Buyers not in subscribe_df:\", len(buyers - subscribers))\n",
    "\n",
    "    print(\"\\n=== PRICE & TIMEFRAME ===\")\n",
    "    print(\"Price distribution:\\n\", buy_df['price'].value_counts())\n",
    "    print(\"Read timeframe:\", read_df['datetime'].min(), \"->\", read_df['datetime'].max())\n",
    "    print(\"Subscribe timeframe:\", subscribe_df['datetime'].min(), \"->\", subscribe_df['datetime'].max())\n",
    "    print(\"Buy timeframe:\", buy_df['datetime'].min(), \"->\", buy_df['datetime'].max())\n",
    "\n",
    "    print(\"\\n=== UNIQUENESS IN READ_DF ===\")\n",
    "    print(\"Total reads:\", len(read_df))\n",
    "    print(\"Unique user-topic pairs:\", read_df[['user_id', 'topic']].drop_duplicates().shape[0])\n",
    "    print(\"Unique user-country pairs:\", read_df[['user_id', 'country']].drop_duplicates().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASIC STRUCTURE & NULLS ===\n",
      "\n",
      "READ DF SHAPE: (581877, 6)\n",
      "read nulls:\n",
      " datetime      0\n",
      "event_type    0\n",
      "country       0\n",
      "user_id       0\n",
      "source        0\n",
      "topic         0\n",
      "dtype: int64\n",
      "read dtypes:\n",
      " datetime      datetime64[ns]\n",
      "event_type            object\n",
      "country               object\n",
      "user_id               object\n",
      "source                object\n",
      "topic                 object\n",
      "dtype: object\n",
      "\n",
      "SUBSCRIBE DF SHAPE: (7618, 3)\n",
      "subscribe nulls:\n",
      " datetime      0\n",
      "event_type    0\n",
      "user_id       0\n",
      "dtype: int64\n",
      "subscribe dtypes:\n",
      " datetime      datetime64[ns]\n",
      "event_type            object\n",
      "user_id               object\n",
      "dtype: object\n",
      "\n",
      "BUY DF SHAPE: (8407, 4)\n",
      "buy nulls:\n",
      " datetime      0\n",
      "event_type    0\n",
      "user_id       0\n",
      "price         0\n",
      "dtype: int64\n",
      "buy dtypes:\n",
      " datetime      datetime64[ns]\n",
      "event_type            object\n",
      "user_id               object\n",
      "price                  int64\n",
      "dtype: object\n",
      "\n",
      "=== UNIQUE VALUES IN READ_DF ===\n",
      "Countries: ['country_7' 'country_8' 'country_6' 'country_2' 'country_5' 'country_4'\n",
      " 'country_3' 'country_1']\n",
      "Sources: ['SEO' 'AdWords' 'Reddit' 'Returning']\n",
      "Topics: ['North America' 'South America' 'Africa' 'Europe' 'Asia' 'Australia']\n",
      "\n",
      "=== VALUE CHECKS ===\n",
      "Invalid countries:\n",
      " Empty DataFrame\n",
      "Columns: [datetime, event_type, country, user_id, source, topic]\n",
      "Index: []\n",
      "Invalid sources:\n",
      " Empty DataFrame\n",
      "Columns: [datetime, event_type, country, user_id, source, topic]\n",
      "Index: []\n",
      "\n",
      "=== DUPLICATE CHECKS ===\n",
      "Duplicate read events: 0\n",
      "Duplicate subscriptions: 0\n",
      "\n",
      "=== USER ACTIVITY ===\n",
      "Reads per user (top 10):\n",
      " user_id\n",
      "2458174315    58\n",
      "2458280511    52\n",
      "2458197594    52\n",
      "2458203397    52\n",
      "2458284001    52\n",
      "2458194192    50\n",
      "2458179454    50\n",
      "2458245790    49\n",
      "2458158385    48\n",
      "2458153661    48\n",
      "Name: count, dtype: int64\n",
      "Subscribers not in read_df: 0\n",
      "Buyers not in read_df: 0\n",
      "Buyers not in subscribe_df: 1572\n",
      "\n",
      "=== PRICE & TIMEFRAME ===\n",
      "Price distribution:\n",
      " price\n",
      "8     6640\n",
      "80    1767\n",
      "Name: count, dtype: int64\n",
      "Read timeframe: 2018-01-01 00:01:01 -> 2018-03-31 05:04:50\n",
      "Subscribe timeframe: 2018-01-01 00:07:41 -> 2018-03-30 23:48:48\n",
      "Buy timeframe: 2018-01-01 04:04:59 -> 2018-03-30 23:56:01\n",
      "\n",
      "=== UNIQUENESS IN READ_DF ===\n",
      "Total reads: 581877\n",
      "Unique user-topic pairs: 353631\n",
      "Unique user-country pairs: 210023\n"
     ]
    }
   ],
   "source": [
    "validate_dataframes(read_df, subscribe_df, buy_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
